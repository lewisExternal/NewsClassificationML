{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string\n",
    "from string import digits\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#Download the necessary datasets\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description       date  \n",
       "0  She left her husband. He killed their children... 2018-05-26  \n",
       "1                           Of course it has a song. 2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data \n",
    "df = pd.read_json('News_Category_Dataset_v2.json', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-9068c8991ab7>:2: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.describe()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "      <td>200853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>41</td>\n",
       "      <td>199344</td>\n",
       "      <td>27993</td>\n",
       "      <td>200812</td>\n",
       "      <td>178353</td>\n",
       "      <td>2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Sunday Roundup</td>\n",
       "      <td></td>\n",
       "      <td>https://www.huffingtonpost.comhttps://www.wash...</td>\n",
       "      <td></td>\n",
       "      <td>2013-01-17 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>32739</td>\n",
       "      <td>90</td>\n",
       "      <td>36620</td>\n",
       "      <td>2</td>\n",
       "      <td>19712</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-05-26 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category        headline authors  \\\n",
       "count     200853          200853  200853   \n",
       "unique        41          199344   27993   \n",
       "top     POLITICS  Sunday Roundup           \n",
       "freq       32739              90   36620   \n",
       "first        NaN             NaN     NaN   \n",
       "last         NaN             NaN     NaN   \n",
       "\n",
       "                                                     link short_description  \\\n",
       "count                                              200853            200853   \n",
       "unique                                             200812            178353   \n",
       "top     https://www.huffingtonpost.comhttps://www.wash...                     \n",
       "freq                                                    2             19712   \n",
       "first                                                 NaN               NaN   \n",
       "last                                                  NaN               NaN   \n",
       "\n",
       "                       date  \n",
       "count                200853  \n",
       "unique                 2309  \n",
       "top     2013-01-17 00:00:00  \n",
       "freq                    100  \n",
       "first   2012-01-28 00:00:00  \n",
       "last    2018-05-26 00:00:00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the datatset \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS          32739\n",
       "WELLNESS          17827\n",
       "ENTERTAINMENT     16058\n",
       "TRAVEL             9887\n",
       "STYLE & BEAUTY     9649\n",
       "PARENTING          8677\n",
       "HEALTHY LIVING     6694\n",
       "QUEER VOICES       6314\n",
       "FOOD & DRINK       6226\n",
       "BUSINESS           5937\n",
       "COMEDY             5175\n",
       "SPORTS             4884\n",
       "BLACK VOICES       4528\n",
       "HOME & LIVING      4195\n",
       "PARENTS            3955\n",
       "THE WORLDPOST      3664\n",
       "WEDDINGS           3651\n",
       "WOMEN              3490\n",
       "IMPACT             3459\n",
       "DIVORCE            3426\n",
       "CRIME              3405\n",
       "MEDIA              2815\n",
       "WEIRD NEWS         2670\n",
       "GREEN              2622\n",
       "WORLDPOST          2579\n",
       "RELIGION           2556\n",
       "STYLE              2254\n",
       "SCIENCE            2178\n",
       "WORLD NEWS         2177\n",
       "TASTE              2096\n",
       "TECH               2082\n",
       "MONEY              1707\n",
       "ARTS               1509\n",
       "FIFTY              1401\n",
       "GOOD NEWS          1398\n",
       "ARTS & CULTURE     1339\n",
       "ENVIRONMENT        1323\n",
       "COLLEGE            1144\n",
       "LATINO VOICES      1129\n",
       "CULTURE & ARTS     1030\n",
       "EDUCATION          1004\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number by catergories \n",
    "df['category'].value_counts() #.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    mass shootings texas last week tv\n",
       "1    smith joins diplo nicky jam world cups officia...\n",
       "2                    hugh grant marries first time age\n",
       "3    jim carrey blasts castrato adam schiff democra...\n",
       "4    julianna margulies uses donald trump poop bags...\n",
       "Name: headline_cleansed, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text pre-processing\n",
    "# There are actually many methods to convert a corpus to a vector format. \n",
    "# The simplest is the the bag-of-words approach, where each unique word in a text will be represented by one number.\n",
    "\n",
    "# remove punctuation & lower \n",
    "df['headline_cleansed'] = df['headline'].apply(lambda x: (''.join([char for char in x if char not in string.punctuation])).lower())\n",
    "\n",
    "# remove numeric characters \n",
    "df['headline_cleansed'] = df['headline_cleansed'].str.replace('\\d+', '')\n",
    "\n",
    "# stem words \n",
    "porter = PorterStemmer()\n",
    "df['headline_cleansed'] = df['headline_cleansed'].apply(lambda x: porter.stem(x))\n",
    "\n",
    "# remove any stopwords\n",
    "df['headline_cleansed'] = df['headline_cleansed'].apply(lambda x: [word for word in x.split() if word not in stopwords.words('english')] )\n",
    "\n",
    "# create the sentence with spaces \n",
    "df['headline_cleansed'] = df['headline_cleansed'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# sample output \n",
    "df['headline_cleansed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use .transform on our Bag-of-Words (bow) transformed object and transform the entire DataFrame of messages. \n",
    "# So what is TF-IDF?\n",
    "# TF-IDF stands for term frequency-inverse document frequenc\n",
    "# TF: Term Frequency, which measures how frequently a term occurs in a document. \n",
    "# Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones.\n",
    "# TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
    "# TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "# IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
    "# IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(df['headline_cleansed'], df['category'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lewis James\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lewis James\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.00      0.00      0.00         0\n",
      "ARTS & CULTURE       0.00      0.00      0.00         0\n",
      "  BLACK VOICES       0.00      0.67      0.01         6\n",
      "      BUSINESS       0.05      0.79      0.10        76\n",
      "       COLLEGE       0.00      0.00      0.00         0\n",
      "        COMEDY       0.04      0.91      0.08        47\n",
      "         CRIME       0.06      0.78      0.11        49\n",
      "CULTURE & ARTS       0.01      1.00      0.02         2\n",
      "       DIVORCE       0.14      0.95      0.24       100\n",
      "     EDUCATION       0.00      0.00      0.00         0\n",
      " ENTERTAINMENT       0.76      0.43      0.55      5616\n",
      "   ENVIRONMENT       0.04      1.00      0.08        12\n",
      "         FIFTY       0.00      0.00      0.00         0\n",
      "  FOOD & DRINK       0.50      0.71      0.59       887\n",
      "     GOOD NEWS       0.00      0.00      0.00         0\n",
      "         GREEN       0.00      1.00      0.01         2\n",
      "HEALTHY LIVING       0.00      0.38      0.00         8\n",
      " HOME & LIVING       0.29      0.93      0.45       270\n",
      "        IMPACT       0.00      0.00      0.00         1\n",
      " LATINO VOICES       0.00      0.00      0.00         0\n",
      "         MEDIA       0.00      0.00      0.00         0\n",
      "         MONEY       0.00      0.00      0.00         0\n",
      "     PARENTING       0.28      0.52      0.36       933\n",
      "       PARENTS       0.02      0.94      0.04        16\n",
      "      POLITICS       0.98      0.31      0.47     20731\n",
      "  QUEER VOICES       0.16      0.88      0.27       236\n",
      "      RELIGION       0.01      0.83      0.02         6\n",
      "       SCIENCE       0.02      0.91      0.04        11\n",
      "        SPORTS       0.17      0.89      0.28       192\n",
      "         STYLE       0.00      0.00      0.00         0\n",
      "STYLE & BEAUTY       0.68      0.69      0.69      1973\n",
      "         TASTE       0.00      0.00      0.00         0\n",
      "          TECH       0.03      1.00      0.05        11\n",
      " THE WORLDPOST       0.05      0.70      0.09        50\n",
      "        TRAVEL       0.56      0.70      0.62      1606\n",
      "      WEDDINGS       0.18      0.97      0.30       141\n",
      "    WEIRD NEWS       0.00      0.00      0.00         0\n",
      "      WELLNESS       0.76      0.37      0.50      7163\n",
      "         WOMEN       0.03      0.96      0.06        25\n",
      "    WORLD NEWS       0.00      1.00      0.00         1\n",
      "     WORLDPOST       0.00      0.00      0.00         0\n",
      "\n",
      "      accuracy                           0.40     40171\n",
      "     macro avg       0.14      0.52      0.15     40171\n",
      "  weighted avg       0.83      0.40      0.49     40171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lewis James\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('svm_classifier', SGDClassifier()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('svm_classifier', SGDClassifier())])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm_pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.11      0.23      0.15       150\n",
      "ARTS & CULTURE       0.11      0.29      0.15       105\n",
      "  BLACK VOICES       0.27      0.48      0.35       503\n",
      "      BUSINESS       0.35      0.45      0.40       864\n",
      "       COLLEGE       0.30      0.46      0.36       158\n",
      "        COMEDY       0.33      0.54      0.41       656\n",
      "         CRIME       0.48      0.48      0.48       655\n",
      "CULTURE & ARTS       0.18      0.43      0.25        93\n",
      "       DIVORCE       0.68      0.70      0.69       676\n",
      "     EDUCATION       0.19      0.40      0.26        91\n",
      " ENTERTAINMENT       0.69      0.55      0.61      3982\n",
      "   ENVIRONMENT       0.19      0.37      0.25       140\n",
      "         FIFTY       0.07      0.21      0.11        95\n",
      "  FOOD & DRINK       0.69      0.56      0.62      1562\n",
      "     GOOD NEWS       0.12      0.26      0.17       133\n",
      "         GREEN       0.20      0.42      0.27       245\n",
      "HEALTHY LIVING       0.08      0.27      0.12       397\n",
      " HOME & LIVING       0.65      0.62      0.64       885\n",
      "        IMPACT       0.15      0.34      0.20       304\n",
      " LATINO VOICES       0.26      0.51      0.34       107\n",
      "         MEDIA       0.27      0.46      0.34       323\n",
      "         MONEY       0.23      0.49      0.31       167\n",
      "     PARENTING       0.51      0.47      0.49      1887\n",
      "       PARENTS       0.10      0.33      0.16       243\n",
      "      POLITICS       0.87      0.59      0.70      9602\n",
      "  QUEER VOICES       0.65      0.66      0.66      1266\n",
      "      RELIGION       0.41      0.54      0.46       376\n",
      "       SCIENCE       0.36      0.49      0.42       328\n",
      "        SPORTS       0.63      0.62      0.62      1039\n",
      "         STYLE       0.05      0.21      0.07        99\n",
      "STYLE & BEAUTY       0.78      0.60      0.68      2604\n",
      "         TASTE       0.07      0.25      0.10       119\n",
      "          TECH       0.37      0.54      0.44       300\n",
      " THE WORLDPOST       0.33      0.49      0.39       494\n",
      "        TRAVEL       0.74      0.59      0.66      2504\n",
      "      WEDDINGS       0.75      0.67      0.71       857\n",
      "    WEIRD NEWS       0.17      0.34      0.23       257\n",
      "      WELLNESS       0.70      0.47      0.57      5113\n",
      "         WOMEN       0.19      0.33      0.24       417\n",
      "    WORLD NEWS       0.15      0.38      0.21       164\n",
      "     WORLDPOST       0.14      0.36      0.21       211\n",
      "\n",
      "      accuracy                           0.54     40171\n",
      "     macro avg       0.36      0.45      0.38     40171\n",
      "  weighted avg       0.65      0.54      0.58     40171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(svm_predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIME'], dtype='<U14')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model on BBC headlines \n",
    "svm_pipeline.predict(np.array([\"four men arrested in anti Semitism video investigation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TRAVEL'], dtype='<U14')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipeline.predict(np.array([\"restaurants and pubs are reopening inside but what are the rules\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GREEN'], dtype='<U14')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipeline.predict(np.array([\"the mid-air walkways saving endangered animals\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
